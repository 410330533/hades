# 利用多进程提高效率
最近因工作需要，对接外部系统仓库接口。

问题：单进程发请求，1个请求1单，从发出，到收到回应，需要1s。这样的话，1h简单点算，也就3600单，这样的速度满足不了需求。

解决方法：单进程解决不了，那只能考虑并发的去发请求。那并发，是用多线程？还是多进程？（进程和线程的区别这里不讲了，自己网上找）
- 线程
    据我所知，php之前应该是一直没有线程，有也是假的，是通过各种方法模拟的。但是这次我似乎找到了一个真的多线程 [pthreads](http://docs.php.net/manual/en/book.pthreads.php)。如果使用线程，对我来说，需要一些学习成本，多线程内存空间共享，写的时候，也有可能会遇到一些坑。
- 进程
    多进程，暂时想到2种实现方法
        - [pcntl_*](http://cn2.php.net/manual/en/book.pcntl.php)
            这种实现，实际在symfony中使用，遇到了问题。原因应该是fork的时候，复制了内存，然后因为entityManager是单例的，flush的时候，mysql可能有做校验。反正抛异常了。
        - shell
            可以使用 `&` 和 `wait` 得到多进程的目的
- curl_multi_*
    单就并发请求这个事来说，curl_multi_*系列函数也能达到这个目的，不过通用性不如上面两种。

那需要下载100个订单，10个进程并发，如何合理的分配给每个进程呢？每个进程分配给多少呢？

现在的做法是，直接用queueId mod 10，每个进程刚好分到10个。

更优的做法是，每个进程，处理完1个请求，再去取新的数据。这样能做到负载均衡。
